{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:52.910157Z",
     "start_time": "2024-04-03T20:56:52.906521Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/Users/mikolajmroz/Developer/Computational_Intelligence_Methods')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\Documents\\Computational_Intelligence_Methods\\Computational_Intelligence_Methods\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('c:\\\\Users\\\\mikol\\\\Documents\\\\Computational_Intelligence_Methods\\\\Computational_Intelligence_Methods')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.398485Z",
     "start_time": "2024-04-03T20:56:53.396306Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.483951Z",
     "start_time": "2024-04-03T20:56:53.482169Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    \"\"\"Linear activation function: f(x) = x\"\"\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.561443Z",
     "start_time": "2024-04-03T20:56:53.559780Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def linear_derivative(x):\n",
    "    \"\"\"Derivative of linear activation function: f'(x) = 1\"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.648639Z",
     "start_time": "2024-04-03T20:56:53.647043Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.735437Z",
     "start_time": "2024-04-03T20:56:53.733706Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.816554Z",
     "start_time": "2024-04-03T20:56:53.814740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)  # Avoid overflow\n",
    "    return np.where(x > 0, 1 / (1 + np.exp(-x)), np.exp(x) / (1 + np.exp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.900712Z",
     "start_time": "2024-04-03T20:56:53.899013Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(sigmoid_output):\n",
    "    # Assumes that sigmoid_output is the result of sigmoid(x)\n",
    "    return sigmoid_output * (1 - sigmoid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:53.982759Z",
     "start_time": "2024-04-03T20:56:53.981155Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    \"\"\"Tanh activation function: f(x) = tanh(x)\"\"\"\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.066052Z",
     "start_time": "2024-04-03T20:56:54.064313Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tanh_derivative(x):\n",
    "    \"\"\"Derivative of tanh activation function: f'(x) = 1 - tanh(x)^2\"\"\"\n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.149254Z",
     "start_time": "2024-04-03T20:56:54.147612Z"
    }
   },
   "outputs": [],
   "source": [
    "def mse(predictions, targets):\n",
    "    return np.mean((predictions - targets) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.232845Z",
     "start_time": "2024-04-03T20:56:54.231100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return exp_x / exp_x.sum(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.315427Z",
     "start_time": "2024-04-03T20:56:54.313595Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(softmax_output, y_true):\n",
    "    # Assuming y_true is one-hot encoded\n",
    "    m = y_true.shape[1]  # Number of examples\n",
    "    log_likelihood = -np.log(softmax_output[y_true.argmax(axis=0), range(m)] + 1e-9)  # Small constant added\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.397839Z",
     "start_time": "2024-04-03T20:56:54.396023Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_derivative(softmax_output, y_true):\n",
    "\n",
    "    corrected_softmax_output = softmax_output - y_true\n",
    "    \n",
    "    return corrected_softmax_output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.606752Z",
     "start_time": "2024-04-03T20:56:54.604904Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax_derivative(softmax_output):\n",
    "    # For softmax combined with cross-entropy loss, the derivative simplifies\n",
    "    # the gradient calculation in backpropagation, directly using output error.\n",
    "    return softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.810306Z",
     "start_time": "2024-04-03T20:56:54.761214Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, sizes, activation_fn=sigmoid, activation_fn_derivative=sigmoid_derivative):\n",
    "        self.layer_sizes = sizes\n",
    "        self.activation_fn = activation_fn\n",
    "        self.layer_weights = [np.random.randn(y, x) * np.sqrt(2. / x) / 10 for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.layer_biases = [np.zeros((y, 1)) for y in sizes[1:]]\n",
    "        self.activation_fn_derivative = activation_fn_derivative\n",
    "\n",
    "    def display_weights_biases(self):\n",
    "        print(\"Final Weights and Biases:\")\n",
    "        for layer_index, (weights, biases) in enumerate(zip(self.layer_weights, self.layer_biases)):\n",
    "            print(f\"Layer {layer_index + 1} Weights:\\n{weights}\")\n",
    "            print(f\"Layer {layer_index + 1} Biases:\\n{biases}\")\n",
    "\n",
    "    def propagate_forward(self, input_activation):\n",
    "        activations = [input_activation]\n",
    "        for biases, weights in zip(self.layer_biases, self.layer_weights[:-1]):\n",
    "            input_activation = self.activation_fn(np.dot(weights, input_activation) + biases)\n",
    "            activations.append(input_activation)\n",
    "        final_input = np.dot(self.layer_weights[-1], input_activation) + self.layer_biases[-1]\n",
    "        output_activation = softmax(final_input)\n",
    "        activations.append(output_activation)\n",
    "        # change\n",
    "        return output_activation, activations\n",
    "\n",
    "    def backward_propagation(self, input_val, true_val):\n",
    "        weight_gradients = [np.zeros(weight.shape) for weight in self.layer_weights]\n",
    "        bias_gradients = [np.zeros(bias.shape) for bias in self.layer_biases]\n",
    "        \n",
    "        # Forward pass to get activations\n",
    "        final_act, activations = self.propagate_forward(input_val)\n",
    "        \n",
    "        # Start with the derivative of the loss function w.r.t. the final activation\n",
    "        error = cross_entropy_derivative(final_act, true_val)\n",
    "        \n",
    "        # Update gradients for the output layer\n",
    "        bias_gradients[-1] = error\n",
    "        weight_gradients[-1] = np.dot(error, activations[-2].T)\n",
    "        \n",
    "        # Backpropagate the error\n",
    "        for l in range(2, len(self.layer_sizes)):\n",
    "            # The derivative of the activation function is applied to the output of the activation function\n",
    "            # from the forward pass, hence 'activations[-l]'\n",
    "            activation_derivative = self.activation_fn_derivative(activations[-l])\n",
    "            \n",
    "            # Correct error propagation\n",
    "            error = np.dot(self.layer_weights[-l+1].T, error) * activation_derivative\n",
    "            \n",
    "            bias_gradients[-l] = error\n",
    "            weight_gradients[-l] = np.dot(error, activations[-l-1].T)\n",
    "        \n",
    "        return weight_gradients, bias_gradients\n",
    "\n",
    "    \n",
    "    def update_batch(self, batch, learn_rate, regularization, total_size, optimization_method, beta, epsilon=1e-8):\n",
    "        gradient_w = [np.zeros(weight.shape) for weight in self.layer_weights]\n",
    "        gradient_b = [np.zeros(bias.shape) for bias in self.layer_biases]\n",
    "        \n",
    "        for input_val, true_val in batch:\n",
    "            delta_gradient_w, delta_gradient_b = self.backward_propagation(input_val, true_val)\n",
    "            gradient_w = [w + dw for w, dw in zip(gradient_w, delta_gradient_w)]\n",
    "            gradient_b = [b + db for b, db in zip(gradient_b, delta_gradient_b)]\n",
    "\n",
    "        # Update rule for weights and biases based on the optimization method\n",
    "        if optimization_method == 'momentum':\n",
    "            # Momentum initialization\n",
    "            if not hasattr(self, 'velocity_weights'):\n",
    "                self.velocity_weights = [np.zeros_like(w) for w in self.layer_weights]\n",
    "                self.velocity_biases = [np.zeros_like(b) for b in self.layer_biases]\n",
    "\n",
    "            # Update velocities\n",
    "            self.velocity_weights = [beta * vw + (1 - beta) * gw / len(batch) for vw, gw in zip(self.velocity_weights, gradient_w)]\n",
    "            self.velocity_biases = [beta * vb + (1 - beta) * gb / len(batch) for vb, gb in zip(self.velocity_biases, gradient_b)]\n",
    "            \n",
    "            # Update weights and biases\n",
    "            self.layer_weights = [(1 - learn_rate * (regularization / total_size)) * w - learn_rate * vw\n",
    "                                  for w, vw in zip(self.layer_weights, self.velocity_weights)]\n",
    "            self.layer_biases = [b - learn_rate * vb for b, vb in zip(self.layer_biases, self.velocity_biases)]\n",
    "        elif optimization_method == 'rmsprop':\n",
    "            # RMSprop initialization\n",
    "            if not hasattr(self, 'squared_gradients_weights'):\n",
    "                self.squared_gradients_weights = [np.zeros_like(w) for w in self.layer_weights]\n",
    "                self.squared_gradients_biases = [np.zeros_like(b) for b in self.layer_biases]\n",
    "\n",
    "            # Update squared gradients\n",
    "            self.squared_gradients_weights = [beta * sgw + (1 - beta) * (gw**2) / len(batch)\n",
    "                                              for sgw, gw in zip(self.squared_gradients_weights, gradient_w)]\n",
    "            self.squared_gradients_biases = [beta * sgb + (1 - beta) * (gb**2) / len(batch)\n",
    "                                             for sgb, gb in zip(self.squared_gradients_biases, gradient_b)]\n",
    "            \n",
    "            # Update weights and biases\n",
    "            self.layer_weights = [(1 - learn_rate * (regularization / total_size)) * w - \n",
    "                                  learn_rate * gw / (np.sqrt(sgw) + epsilon)\n",
    "                                  for w, sgw, gw in zip(self.layer_weights, self.squared_gradients_weights, gradient_w)]\n",
    "            self.layer_biases = [b - learn_rate * gb / (np.sqrt(sgb) + epsilon)\n",
    "                                 for b, sgb, gb in zip(self.layer_biases, self.squared_gradients_biases, gradient_b)]\n",
    "\n",
    "    def train(self, training_data, epochs, learn_rate, batch_size, regularization=0.0, optimization_method='rmsprop', beta=0.9, epsilon=1e-8, visual_interval=10, X_val=None, y_val=None, target = None,adaptive_learn_rate = True, decay_rate=0.1, decay_step=100):\n",
    "        n = len(training_data)\n",
    "\n",
    "        f1_history = []\n",
    "        \n",
    "        # Determine mini-batch size based on whether the batch_size_input is a percentage or fixed value\n",
    "        if isinstance(batch_size, float):  # If batch_size_input is a float, treat it as a percentage\n",
    "            batch_size = max(1, min(n, int(n * batch_size / 100)))\n",
    "        elif isinstance(batch_size, int):  # If batch_size_input is an integer, treat it as a fixed size\n",
    "            batch_size = max(1, min(n, batch_size))\n",
    "        else:  # Raise an error if batch_size_input is neither float nor int\n",
    "            raise ValueError(\"batch_size_input must be an integer (fixed size) or a float (percentage of dataset)\")\n",
    "        \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k + batch_size] for k in range(0, n, batch_size)]\n",
    "    \n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_batch(mini_batch, learn_rate, regularization, n, optimization_method, beta, epsilon)\n",
    "            if adaptive_learn_rate:\n",
    "                # Decay the learning rate every decay_step epochs\n",
    "                if epoch % decay_step == 0 and epoch > 0:\n",
    "                    learn_rate *= (1. / (1. + decay_rate * epoch))\n",
    "    \n",
    "            if epoch % visual_interval == 0:\n",
    "                predictions = np.argmax(np.array([self.propagate_forward(x.reshape(-1, 1))[0] for x in X_val]), axis=1)\n",
    "                accuracy = np.mean(predictions == y_val)\n",
    "                print(f'epoch: {epoch}', f'Test accuracy: {accuracy}')\n",
    "                \n",
    "                f1_weighted = f1_score(y_val, predictions, average='weighted')\n",
    "                f1_history.append((epoch,f1_weighted))\n",
    "                print(f\"F1 Score (Weighted): {f1_weighted}\")\n",
    "                \n",
    "                if f1_weighted > target:\n",
    "                    break\n",
    "        return f1_history\n",
    "\n",
    "    def visualize_network(self):\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "        # For each layer\n",
    "        for i in range(len(self.layer_sizes)):\n",
    "            # Draw the nodes of the layer\n",
    "            ax.scatter([i]*self.layer_sizes[i], range(self.layer_sizes[i]))\n",
    "    \n",
    "            # Draw the weights connecting the nodes of the current layer to the next layer\n",
    "            if i < len(self.layer_sizes) - 1:\n",
    "                for j in range(self.layer_sizes[i]):\n",
    "                    for k in range(self.layer_sizes[i+1]):\n",
    "                        weight = self.layer_weights[i][k, j]\n",
    "                        color = 'g' if weight >= 0 else 'r'\n",
    "                        ax.plot([i, i+1], [j, k], color=color)\n",
    "                        # Add weight value on the line\n",
    "                        ax.text(i + 0.5, (j + k) / 2, f'{weight:.2f}', color=color, ha='center')\n",
    "    \n",
    "            \n",
    "    \n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:54.898949Z",
     "start_time": "2024-04-03T20:56:54.895568Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataScaler:\n",
    "    def __init__(self, method=\"standardization\"):\n",
    "        self.method = method\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        if self.method == \"min_max\":\n",
    "            return self.fit_transform_min_max(data)\n",
    "        elif self.method == \"standardization\":\n",
    "            return self.fit_transform_standardization(data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported scaling method\")\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.method == \"min_max\":\n",
    "            return self.transform_min_max(data)\n",
    "        elif self.method == \"standardization\":\n",
    "            return self.transform_standardization(data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported scaling method\")\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        if self.method == \"min_max\":\n",
    "            return self.inverse_transform_min_max(data)\n",
    "        elif self.method == \"standardization\":\n",
    "            return self.inverse_transform_standardization(data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported scaling method\")\n",
    "\n",
    "    def fit_transform_min_max(self, data):\n",
    "        self.min = np.min(data, axis=0)\n",
    "        self.max = np.max(data, axis=0)\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "\n",
    "    def transform_min_max(self, data):\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "\n",
    "    def inverse_transform_min_max(self, data):\n",
    "        return data * (self.max - self.min) + self.min\n",
    "\n",
    "    def fit_transform_standardization(self, data):\n",
    "        self.mean = np.mean(data, axis=0)\n",
    "        self.std = np.std(data, axis=0)\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def transform_standardization(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform_standardization(self, data):\n",
    "        return data * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:55.032298Z",
     "start_time": "2024-04-03T20:56:55.030500Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mse(mse_history):\n",
    "    plt.plot(mse_history)\n",
    "    plt.title('MSE Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:55.322006Z",
     "start_time": "2024-04-03T20:56:55.315652Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_rings3_regular = pd.read_csv('./data/classification/rings3-regular-training.csv')\n",
    "df_test_rings3_regular = pd.read_csv('./data/classification/rings3-regular-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:55.509414Z",
     "start_time": "2024-04-03T20:56:55.504738Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_easy = pd.read_csv('./data/classification/easy-training.csv')\n",
    "df_test_easy = pd.read_csv('./data/classification/easy-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:56:55.671580Z",
     "start_time": "2024-04-03T20:56:55.667133Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train_xor3 = pd.read_csv('./data/classification/xor3-training.csv')\n",
    "df_test_xor3 = pd.read_csv('./data/classification/xor3-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:02:46.546202Z",
     "start_time": "2024-04-03T21:02:46.539505Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train_rings5_regular = pd.read_csv('./data/classification/rings5-regular-training.csv')\n",
    "df_test_rings5_regular = pd.read_csv('./data/classification/rings5-regular-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### rings 3 regular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:04.448828Z",
     "start_time": "2024-04-03T20:57:04.446396Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scaler_X = DataScaler(\"standardization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:04.580953Z",
     "start_time": "2024-04-03T20:57:04.578500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "X1_train_rings = df_train_rings3_regular[['x']].values.reshape(-1, 1)\n",
    "X1_test_rings = df_test_rings3_regular[['x']].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:04.734400Z",
     "start_time": "2024-04-03T20:57:04.732253Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X2_train_rings = df_train_rings3_regular[['y']].values.reshape(-1, 1)\n",
    "X2_test_rings = df_test_rings3_regular[['y']].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:04.886356Z",
     "start_time": "2024-04-03T20:57:04.884223Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_rings = np.hstack((X1_train_rings, X2_train_rings))\n",
    "X_test_rings = np.hstack((X1_test_rings, X2_test_rings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:05.026647Z",
     "start_time": "2024-04-03T20:57:05.024389Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_rings_scaled = np.hstack((scaler_X.fit_transform(X1_train_rings), scaler_X.fit_transform(X2_train_rings)))\n",
    "X_test_rings_scaled = np.hstack((scaler_X.transform(X1_test_rings), scaler_X.transform(X2_test_rings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:05.183108Z",
     "start_time": "2024-04-03T20:57:05.181162Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_train_rings = df_train_rings3_regular['c'].values.reshape(-1, 1)\n",
    "y_test_rings = df_test_rings3_regular['c'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:05.322903Z",
     "start_time": "2024-04-03T20:57:05.319995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the 'c' column into one-hot vectors for the training and test datasets\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded_rings = encoder.fit_transform(y_train_rings)\n",
    "y_test_encoded_rings = encoder.transform(y_test_rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:05.476831Z",
     "start_time": "2024-04-03T20:57:05.474490Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_rings = y_train_encoded_rings.shape[1] \n",
    "num_classes_rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:57:06.638726Z",
     "start_time": "2024-04-03T20:57:06.634874Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_data_rings = [\n",
    "    (X_train_rings[i].reshape(-1, 1), y_train_encoded_rings[i].reshape(-1, 1))\n",
    "    for i in range(len(X_train_rings))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T20:59:02.258766Z",
     "start_time": "2024-04-03T20:59:00.132130Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.585\n",
      "F1 Score (Weighted): 0.5216714539031263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 Test accuracy: 0.6085\n",
      "F1 Score (Weighted): 0.6105352864582114\n",
      "epoch: 20 Test accuracy: 0.794\n",
      "F1 Score (Weighted): 0.7915422324741564\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_sigmoid = MLP(sizes=[2, 10, 10, 3], activation_fn=sigmoid,\n",
    "                activation_fn_derivative=sigmoid_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_sigmoid = mlp_rings_sigmoid.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:02:16.744172Z",
     "start_time": "2024-04-03T21:01:43.420341Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.384\n",
      "F1 Score (Weighted): 0.21336416184971096\n",
      "epoch: 10 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 20 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 30 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 40 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 50 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 60 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 70 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 80 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 90 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 100 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 110 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 120 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 130 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 140 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 150 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 160 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 170 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 180 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 190 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 200 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 210 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 220 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 230 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 240 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 250 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 260 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 270 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 280 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 290 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 300 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 310 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 320 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 330 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.21356482484651498\n",
      "epoch: 340 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 350 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 360 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 370 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 380 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 390 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n",
      "epoch: 400 Test accuracy: 0.208\n",
      "F1 Score (Weighted): 0.07162913907284768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m mlp_rings_relu \u001b[38;5;241m=\u001b[39m MLP(sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m], activation_fn\u001b[38;5;241m=\u001b[39mrelu,\n\u001b[0;32m      2\u001b[0m                 activation_fn_derivative\u001b[38;5;241m=\u001b[39mrelu_derivative)  \u001b[38;5;66;03m# Example layer setup\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the MLP using your training data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m f1_relu \u001b[38;5;241m=\u001b[39m \u001b[43mmlp_rings_relu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data_rings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_rings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test_rings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madaptive_learn_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 117\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, training_data, epochs, learn_rate, batch_size, regularization, optimization_method, beta, epsilon, visual_interval, X_val, y_val, target, adaptive_learn_rate, decay_rate, decay_step)\u001b[0m\n\u001b[0;32m    114\u001b[0m mini_batches \u001b[38;5;241m=\u001b[39m [training_data[k:k \u001b[38;5;241m+\u001b[39m batch_size] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n, batch_size)]\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_batch \u001b[38;5;129;01min\u001b[39;00m mini_batches:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimization_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adaptive_learn_rate:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# Decay the learning rate every decay_step epochs\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m decay_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[17], line 60\u001b[0m, in \u001b[0;36mMLP.update_batch\u001b[1;34m(self, batch, learn_rate, regularization, total_size, optimization_method, beta, epsilon)\u001b[0m\n\u001b[0;32m     57\u001b[0m gradient_b \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(bias\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m bias \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_biases]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_val, true_val \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m---> 60\u001b[0m     delta_gradient_w, delta_gradient_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     gradient_w \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;241m+\u001b[39m dw \u001b[38;5;28;01mfor\u001b[39;00m w, dw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(gradient_w, delta_gradient_w)]\n\u001b[0;32m     62\u001b[0m     gradient_b \u001b[38;5;241m=\u001b[39m [b \u001b[38;5;241m+\u001b[39m db \u001b[38;5;28;01mfor\u001b[39;00m b, db \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(gradient_b, delta_gradient_b)]\n",
      "Cell \u001b[1;32mIn[17], line 31\u001b[0m, in \u001b[0;36mMLP.backward_propagation\u001b[1;34m(self, input_val, true_val)\u001b[0m\n\u001b[0;32m     28\u001b[0m bias_gradients \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(bias\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m bias \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_biases]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Forward pass to get activations\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m final_act, activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Start with the derivative of the loss function w.r.t. the final activation\u001b[39;00m\n\u001b[0;32m     34\u001b[0m error \u001b[38;5;241m=\u001b[39m cross_entropy_derivative(final_act, true_val)\n",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m, in \u001b[0;36mMLP.propagate_forward\u001b[1;34m(self, input_activation)\u001b[0m\n\u001b[0;32m     16\u001b[0m activations \u001b[38;5;241m=\u001b[39m [input_activation]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m biases, weights \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_biases, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_weights[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m---> 18\u001b[0m     input_activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_activation\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m biases)\n\u001b[0;32m     19\u001b[0m     activations\u001b[38;5;241m.\u001b[39mappend(input_activation)\n\u001b[0;32m     20\u001b[0m final_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_weights[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], input_activation) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_biases[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_rings_relu = MLP(sizes=[2, 10, 10, 3], activation_fn=relu,\n",
    "                activation_fn_derivative=relu_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_relu = mlp_rings_relu.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:00:05.814966Z",
     "start_time": "2024-04-03T20:59:37.256542Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.4475\n",
      "F1 Score (Weighted): 0.4453187956870763\n",
      "epoch: 10 Test accuracy: 0.557\n",
      "F1 Score (Weighted): 0.5121815168180229\n",
      "epoch: 20 Test accuracy: 0.467\n",
      "F1 Score (Weighted): 0.45612421598716346\n",
      "epoch: 30 Test accuracy: 0.5515\n",
      "F1 Score (Weighted): 0.5368322549359558\n",
      "epoch: 40 Test accuracy: 0.384\n",
      "F1 Score (Weighted): 0.3237195033451202\n",
      "epoch: 50 Test accuracy: 0.4725\n",
      "F1 Score (Weighted): 0.47680612123847055\n",
      "epoch: 60 Test accuracy: 0.4285\n",
      "F1 Score (Weighted): 0.34408223667297766\n",
      "epoch: 70 Test accuracy: 0.395\n",
      "F1 Score (Weighted): 0.3200558256274899\n",
      "epoch: 80 Test accuracy: 0.599\n",
      "F1 Score (Weighted): 0.5297909852453242\n",
      "epoch: 90 Test accuracy: 0.46\n",
      "F1 Score (Weighted): 0.46041553318120954\n",
      "epoch: 100 Test accuracy: 0.532\n",
      "F1 Score (Weighted): 0.5143005632440422\n",
      "epoch: 110 Test accuracy: 0.4905\n",
      "F1 Score (Weighted): 0.47672854109470014\n",
      "epoch: 120 Test accuracy: 0.339\n",
      "F1 Score (Weighted): 0.31388012720417413\n",
      "epoch: 130 Test accuracy: 0.412\n",
      "F1 Score (Weighted): 0.3261529781166564\n",
      "epoch: 140 Test accuracy: 0.5985\n",
      "F1 Score (Weighted): 0.5290697484730256\n",
      "epoch: 150 Test accuracy: 0.4405\n",
      "F1 Score (Weighted): 0.4159074564024172\n",
      "epoch: 160 Test accuracy: 0.397\n",
      "F1 Score (Weighted): 0.3209828695660218\n",
      "epoch: 170 Test accuracy: 0.587\n",
      "F1 Score (Weighted): 0.5187566998917724\n",
      "epoch: 180 Test accuracy: 0.5785\n",
      "F1 Score (Weighted): 0.529441382607155\n",
      "epoch: 190 Test accuracy: 0.586\n",
      "F1 Score (Weighted): 0.5394647576663899\n",
      "epoch: 200 Test accuracy: 0.5975\n",
      "F1 Score (Weighted): 0.528970802814297\n",
      "epoch: 210 Test accuracy: 0.596\n",
      "F1 Score (Weighted): 0.5255143515137898\n",
      "epoch: 220 Test accuracy: 0.405\n",
      "F1 Score (Weighted): 0.4160424804234695\n",
      "epoch: 230 Test accuracy: 0.447\n",
      "F1 Score (Weighted): 0.4573464703245386\n",
      "epoch: 240 Test accuracy: 0.4835\n",
      "F1 Score (Weighted): 0.4571259116603275\n",
      "epoch: 250 Test accuracy: 0.5915\n",
      "F1 Score (Weighted): 0.5219203010531136\n",
      "epoch: 260 Test accuracy: 0.593\n",
      "F1 Score (Weighted): 0.522743742344495\n",
      "epoch: 270 Test accuracy: 0.466\n",
      "F1 Score (Weighted): 0.40978730521983986\n",
      "epoch: 280 Test accuracy: 0.3145\n",
      "F1 Score (Weighted): 0.2952453447613524\n",
      "epoch: 290 Test accuracy: 0.5835\n",
      "F1 Score (Weighted): 0.5317159380415389\n",
      "epoch: 300 Test accuracy: 0.404\n",
      "F1 Score (Weighted): 0.4198893890574086\n",
      "epoch: 310 Test accuracy: 0.595\n",
      "F1 Score (Weighted): 0.5245421584160147\n",
      "epoch: 320 Test accuracy: 0.4905\n",
      "F1 Score (Weighted): 0.4676800790482772\n",
      "epoch: 330 Test accuracy: 0.342\n",
      "F1 Score (Weighted): 0.3517732026745185\n",
      "epoch: 340 Test accuracy: 0.575\n",
      "F1 Score (Weighted): 0.5381305920321502\n",
      "epoch: 350 Test accuracy: 0.3845\n",
      "F1 Score (Weighted): 0.34317847764575377\n",
      "epoch: 360 Test accuracy: 0.5965\n",
      "F1 Score (Weighted): 0.527164464677361\n",
      "epoch: 370 Test accuracy: 0.5685\n",
      "F1 Score (Weighted): 0.5454110345656809\n",
      "epoch: 380 Test accuracy: 0.596\n",
      "F1 Score (Weighted): 0.5251581791945428\n",
      "epoch: 390 Test accuracy: 0.568\n",
      "F1 Score (Weighted): 0.5572588537531759\n",
      "epoch: 400 Test accuracy: 0.439\n",
      "F1 Score (Weighted): 0.4550872283546272\n",
      "epoch: 410 Test accuracy: 0.595\n",
      "F1 Score (Weighted): 0.5243635628966522\n",
      "epoch: 420 Test accuracy: 0.572\n",
      "F1 Score (Weighted): 0.5256805641533803\n",
      "epoch: 430 Test accuracy: 0.5715\n",
      "F1 Score (Weighted): 0.5362813148878877\n",
      "epoch: 440 Test accuracy: 0.5635\n",
      "F1 Score (Weighted): 0.5215310148654294\n",
      "epoch: 450 Test accuracy: 0.4415\n",
      "F1 Score (Weighted): 0.40773383128236795\n",
      "epoch: 460 Test accuracy: 0.386\n",
      "F1 Score (Weighted): 0.310052000947194\n",
      "epoch: 470 Test accuracy: 0.5155\n",
      "F1 Score (Weighted): 0.5004814535102577\n",
      "epoch: 480 Test accuracy: 0.5725\n",
      "F1 Score (Weighted): 0.5063722080545432\n",
      "epoch: 490 Test accuracy: 0.5805\n",
      "F1 Score (Weighted): 0.5411755207090316\n",
      "epoch: 500 Test accuracy: 0.437\n",
      "F1 Score (Weighted): 0.44850788937716074\n",
      "epoch: 510 Test accuracy: 0.446\n",
      "F1 Score (Weighted): 0.42812725954028935\n",
      "epoch: 520 Test accuracy: 0.602\n",
      "F1 Score (Weighted): 0.5497543615405099\n",
      "epoch: 530 Test accuracy: 0.395\n",
      "F1 Score (Weighted): 0.4003024010196929\n",
      "epoch: 540 Test accuracy: 0.4835\n",
      "F1 Score (Weighted): 0.4742684253936824\n",
      "epoch: 550 Test accuracy: 0.5935\n",
      "F1 Score (Weighted): 0.5220003791988602\n",
      "epoch: 560 Test accuracy: 0.544\n",
      "F1 Score (Weighted): 0.5246686670974313\n",
      "epoch: 570 Test accuracy: 0.568\n",
      "F1 Score (Weighted): 0.548313581399489\n",
      "epoch: 580 Test accuracy: 0.528\n",
      "F1 Score (Weighted): 0.5006844321266485\n",
      "epoch: 590 Test accuracy: 0.4195\n",
      "F1 Score (Weighted): 0.3493315239801171\n",
      "epoch: 600 Test accuracy: 0.457\n",
      "F1 Score (Weighted): 0.39959025839272144\n",
      "epoch: 610 Test accuracy: 0.4745\n",
      "F1 Score (Weighted): 0.4600364189006859\n",
      "epoch: 620 Test accuracy: 0.598\n",
      "F1 Score (Weighted): 0.5440948054085513\n",
      "epoch: 630 Test accuracy: 0.596\n",
      "F1 Score (Weighted): 0.5256674573620852\n",
      "epoch: 640 Test accuracy: 0.4645\n",
      "F1 Score (Weighted): 0.44092534596556177\n",
      "epoch: 650 Test accuracy: 0.4385\n",
      "F1 Score (Weighted): 0.3495766101353428\n",
      "epoch: 660 Test accuracy: 0.599\n",
      "F1 Score (Weighted): 0.5286905422977807\n",
      "epoch: 670 Test accuracy: 0.421\n",
      "F1 Score (Weighted): 0.33676737416921343\n",
      "epoch: 680 Test accuracy: 0.608\n",
      "F1 Score (Weighted): 0.5391296770433847\n",
      "epoch: 690 Test accuracy: 0.5815\n",
      "F1 Score (Weighted): 0.5366381992262604\n",
      "epoch: 700 Test accuracy: 0.607\n",
      "F1 Score (Weighted): 0.5385924185019199\n",
      "epoch: 710 Test accuracy: 0.582\n",
      "F1 Score (Weighted): 0.542911769410461\n",
      "epoch: 720 Test accuracy: 0.5815\n",
      "F1 Score (Weighted): 0.5399850735397399\n",
      "epoch: 730 Test accuracy: 0.4965\n",
      "F1 Score (Weighted): 0.49825209975517715\n",
      "epoch: 740 Test accuracy: 0.402\n",
      "F1 Score (Weighted): 0.3175123542436486\n",
      "epoch: 750 Test accuracy: 0.56\n",
      "F1 Score (Weighted): 0.532197486791313\n",
      "epoch: 760 Test accuracy: 0.485\n",
      "F1 Score (Weighted): 0.46255787484443966\n",
      "epoch: 770 Test accuracy: 0.2465\n",
      "F1 Score (Weighted): 0.1619873740448942\n",
      "epoch: 780 Test accuracy: 0.599\n",
      "F1 Score (Weighted): 0.5284491505126861\n",
      "epoch: 790 Test accuracy: 0.5905\n",
      "F1 Score (Weighted): 0.5380109573762815\n",
      "epoch: 800 Test accuracy: 0.552\n",
      "F1 Score (Weighted): 0.522217647702993\n",
      "epoch: 810 Test accuracy: 0.594\n",
      "F1 Score (Weighted): 0.5270654994147482\n",
      "epoch: 820 Test accuracy: 0.5635\n",
      "F1 Score (Weighted): 0.5402274977412217\n",
      "epoch: 830 Test accuracy: 0.5925\n",
      "F1 Score (Weighted): 0.5224095857362342\n",
      "epoch: 840 Test accuracy: 0.463\n",
      "F1 Score (Weighted): 0.40568290721641526\n",
      "epoch: 850 Test accuracy: 0.589\n",
      "F1 Score (Weighted): 0.528079310561609\n",
      "epoch: 860 Test accuracy: 0.426\n",
      "F1 Score (Weighted): 0.42748706505377\n",
      "epoch: 870 Test accuracy: 0.458\n",
      "F1 Score (Weighted): 0.38349016332944075\n",
      "epoch: 880 Test accuracy: 0.5875\n",
      "F1 Score (Weighted): 0.5373306750861002\n",
      "epoch: 890 Test accuracy: 0.4855\n",
      "F1 Score (Weighted): 0.4931441419008371\n",
      "epoch: 900 Test accuracy: 0.495\n",
      "F1 Score (Weighted): 0.42930329557330155\n",
      "epoch: 910 Test accuracy: 0.462\n",
      "F1 Score (Weighted): 0.4409191078123683\n",
      "epoch: 920 Test accuracy: 0.4485\n",
      "F1 Score (Weighted): 0.3777512864690997\n",
      "epoch: 930 Test accuracy: 0.5255\n",
      "F1 Score (Weighted): 0.5079171533202633\n",
      "epoch: 940 Test accuracy: 0.4595\n",
      "F1 Score (Weighted): 0.39042641187251187\n",
      "epoch: 950 Test accuracy: 0.5155\n",
      "F1 Score (Weighted): 0.4967106206996107\n",
      "epoch: 960 Test accuracy: 0.503\n",
      "F1 Score (Weighted): 0.48367061792510885\n",
      "epoch: 970 Test accuracy: 0.3965\n",
      "F1 Score (Weighted): 0.4133333541522426\n",
      "epoch: 980 Test accuracy: 0.5825\n",
      "F1 Score (Weighted): 0.5491225477020226\n",
      "epoch: 990 Test accuracy: 0.54\n",
      "F1 Score (Weighted): 0.5320704901899871\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_tanh = MLP(sizes=[2, 10, 10, 3], activation_fn=tanh,\n",
    "                activation_fn_derivative=tanh_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_tanh = mlp_rings_tanh.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:00:30.302760Z",
     "start_time": "2024-04-03T21:00:05.815699Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.389\n",
      "F1 Score (Weighted): 0.36142709881682705\n",
      "epoch: 10 Test accuracy: 0.393\n",
      "F1 Score (Weighted): 0.391524981262858\n",
      "epoch: 20 Test accuracy: 0.467\n",
      "F1 Score (Weighted): 0.46195998830501567\n",
      "epoch: 30 Test accuracy: 0.413\n",
      "F1 Score (Weighted): 0.36929225049328845\n",
      "epoch: 40 Test accuracy: 0.5445\n",
      "F1 Score (Weighted): 0.48279220968491254\n",
      "epoch: 50 Test accuracy: 0.401\n",
      "F1 Score (Weighted): 0.32438783518262976\n",
      "epoch: 60 Test accuracy: 0.4005\n",
      "F1 Score (Weighted): 0.31994056311949626\n",
      "epoch: 70 Test accuracy: 0.578\n",
      "F1 Score (Weighted): 0.5227157838663086\n",
      "epoch: 80 Test accuracy: 0.3515\n",
      "F1 Score (Weighted): 0.3196537057376341\n",
      "epoch: 90 Test accuracy: 0.4565\n",
      "F1 Score (Weighted): 0.45232138557321117\n",
      "epoch: 100 Test accuracy: 0.499\n",
      "F1 Score (Weighted): 0.47782672024667866\n",
      "epoch: 110 Test accuracy: 0.507\n",
      "F1 Score (Weighted): 0.4495386711241431\n",
      "epoch: 120 Test accuracy: 0.331\n",
      "F1 Score (Weighted): 0.3319395751724311\n",
      "epoch: 130 Test accuracy: 0.314\n",
      "F1 Score (Weighted): 0.3136726230294031\n",
      "epoch: 140 Test accuracy: 0.5885\n",
      "F1 Score (Weighted): 0.5788294119707343\n",
      "epoch: 150 Test accuracy: 0.385\n",
      "F1 Score (Weighted): 0.2624500599045455\n",
      "epoch: 160 Test accuracy: 0.4275\n",
      "F1 Score (Weighted): 0.3736089106112991\n",
      "epoch: 170 Test accuracy: 0.4835\n",
      "F1 Score (Weighted): 0.4759134089420569\n",
      "epoch: 180 Test accuracy: 0.429\n",
      "F1 Score (Weighted): 0.3912775767464052\n",
      "epoch: 190 Test accuracy: 0.4405\n",
      "F1 Score (Weighted): 0.42703069813905525\n",
      "epoch: 200 Test accuracy: 0.4065\n",
      "F1 Score (Weighted): 0.3958782181448898\n",
      "epoch: 210 Test accuracy: 0.4975\n",
      "F1 Score (Weighted): 0.4910356941426641\n",
      "epoch: 220 Test accuracy: 0.4615\n",
      "F1 Score (Weighted): 0.4626382140128545\n",
      "epoch: 230 Test accuracy: 0.3895\n",
      "F1 Score (Weighted): 0.35181615848944076\n",
      "epoch: 240 Test accuracy: 0.5275\n",
      "F1 Score (Weighted): 0.5220548279423514\n",
      "epoch: 250 Test accuracy: 0.406\n",
      "F1 Score (Weighted): 0.3282239170663725\n",
      "epoch: 260 Test accuracy: 0.3875\n",
      "F1 Score (Weighted): 0.37191063517717865\n",
      "epoch: 270 Test accuracy: 0.383\n",
      "F1 Score (Weighted): 0.36202067963254697\n",
      "epoch: 280 Test accuracy: 0.4055\n",
      "F1 Score (Weighted): 0.3231566894335074\n",
      "epoch: 290 Test accuracy: 0.4125\n",
      "F1 Score (Weighted): 0.3726829488645693\n",
      "epoch: 300 Test accuracy: 0.39\n",
      "F1 Score (Weighted): 0.38118024440722603\n",
      "epoch: 310 Test accuracy: 0.51\n",
      "F1 Score (Weighted): 0.4918531598657321\n",
      "epoch: 320 Test accuracy: 0.4915\n",
      "F1 Score (Weighted): 0.4250645805052258\n",
      "epoch: 330 Test accuracy: 0.4635\n",
      "F1 Score (Weighted): 0.45051260616842104\n",
      "epoch: 340 Test accuracy: 0.5675\n",
      "F1 Score (Weighted): 0.5021844678781031\n",
      "epoch: 350 Test accuracy: 0.265\n",
      "F1 Score (Weighted): 0.24812236113665198\n",
      "epoch: 360 Test accuracy: 0.405\n",
      "F1 Score (Weighted): 0.36521501053563166\n",
      "epoch: 370 Test accuracy: 0.402\n",
      "F1 Score (Weighted): 0.31790838284321\n",
      "epoch: 380 Test accuracy: 0.506\n",
      "F1 Score (Weighted): 0.45967627432031954\n",
      "epoch: 390 Test accuracy: 0.378\n",
      "F1 Score (Weighted): 0.323665679878163\n",
      "epoch: 400 Test accuracy: 0.417\n",
      "F1 Score (Weighted): 0.3710596758809444\n",
      "epoch: 410 Test accuracy: 0.364\n",
      "F1 Score (Weighted): 0.3400965217473976\n",
      "epoch: 420 Test accuracy: 0.4225\n",
      "F1 Score (Weighted): 0.4016921194631967\n",
      "epoch: 430 Test accuracy: 0.521\n",
      "F1 Score (Weighted): 0.5143411959385555\n",
      "epoch: 440 Test accuracy: 0.342\n",
      "F1 Score (Weighted): 0.31307809428261735\n",
      "epoch: 450 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.23595914742451154\n",
      "epoch: 460 Test accuracy: 0.5655\n",
      "F1 Score (Weighted): 0.5003979327386693\n",
      "epoch: 470 Test accuracy: 0.4975\n",
      "F1 Score (Weighted): 0.5092722609203795\n",
      "epoch: 480 Test accuracy: 0.406\n",
      "F1 Score (Weighted): 0.41956007226039593\n",
      "epoch: 490 Test accuracy: 0.555\n",
      "F1 Score (Weighted): 0.49136071076908233\n",
      "epoch: 500 Test accuracy: 0.414\n",
      "F1 Score (Weighted): 0.41386964918606883\n",
      "epoch: 510 Test accuracy: 0.4735\n",
      "F1 Score (Weighted): 0.4639254514101153\n",
      "epoch: 520 Test accuracy: 0.427\n",
      "F1 Score (Weighted): 0.33173012561626863\n",
      "epoch: 530 Test accuracy: 0.57\n",
      "F1 Score (Weighted): 0.5090633678661214\n",
      "epoch: 540 Test accuracy: 0.588\n",
      "F1 Score (Weighted): 0.519027335033996\n",
      "epoch: 550 Test accuracy: 0.419\n",
      "F1 Score (Weighted): 0.40646876478872385\n",
      "epoch: 560 Test accuracy: 0.4385\n",
      "F1 Score (Weighted): 0.42992186878182154\n",
      "epoch: 570 Test accuracy: 0.4045\n",
      "F1 Score (Weighted): 0.32144506796923483\n",
      "epoch: 580 Test accuracy: 0.4395\n",
      "F1 Score (Weighted): 0.42653947947504234\n",
      "epoch: 590 Test accuracy: 0.441\n",
      "F1 Score (Weighted): 0.3753599244968471\n",
      "epoch: 600 Test accuracy: 0.237\n",
      "F1 Score (Weighted): 0.18136317625977164\n",
      "epoch: 610 Test accuracy: 0.401\n",
      "F1 Score (Weighted): 0.3498719717707028\n",
      "epoch: 620 Test accuracy: 0.566\n",
      "F1 Score (Weighted): 0.5229763639909314\n",
      "epoch: 630 Test accuracy: 0.3995\n",
      "F1 Score (Weighted): 0.31021433848016955\n",
      "epoch: 640 Test accuracy: 0.387\n",
      "F1 Score (Weighted): 0.3169688633675965\n",
      "epoch: 650 Test accuracy: 0.5895\n",
      "F1 Score (Weighted): 0.5209565152266773\n",
      "epoch: 660 Test accuracy: 0.5115\n",
      "F1 Score (Weighted): 0.5095001862814865\n",
      "epoch: 670 Test accuracy: 0.5545\n",
      "F1 Score (Weighted): 0.49085986654106467\n",
      "epoch: 680 Test accuracy: 0.5595\n",
      "F1 Score (Weighted): 0.5085149975250083\n",
      "epoch: 690 Test accuracy: 0.3745\n",
      "F1 Score (Weighted): 0.31981858524072476\n",
      "epoch: 700 Test accuracy: 0.398\n",
      "F1 Score (Weighted): 0.31674097361173414\n",
      "epoch: 710 Test accuracy: 0.4395\n",
      "F1 Score (Weighted): 0.4295702947739645\n",
      "epoch: 720 Test accuracy: 0.6075\n",
      "F1 Score (Weighted): 0.5939295836830001\n",
      "epoch: 730 Test accuracy: 0.6005\n",
      "F1 Score (Weighted): 0.5874921116498817\n",
      "epoch: 740 Test accuracy: 0.391\n",
      "F1 Score (Weighted): 0.32173562768264\n",
      "epoch: 750 Test accuracy: 0.332\n",
      "F1 Score (Weighted): 0.32296648439239256\n",
      "epoch: 760 Test accuracy: 0.2155\n",
      "F1 Score (Weighted): 0.18822731614209529\n",
      "epoch: 770 Test accuracy: 0.37\n",
      "F1 Score (Weighted): 0.32944030667515173\n",
      "epoch: 780 Test accuracy: 0.4155\n",
      "F1 Score (Weighted): 0.39627715097747523\n",
      "epoch: 790 Test accuracy: 0.443\n",
      "F1 Score (Weighted): 0.3698636949411741\n",
      "epoch: 800 Test accuracy: 0.609\n",
      "F1 Score (Weighted): 0.5964085875826549\n",
      "epoch: 810 Test accuracy: 0.531\n",
      "F1 Score (Weighted): 0.5267496980329666\n",
      "epoch: 820 Test accuracy: 0.4015\n",
      "F1 Score (Weighted): 0.318498190779287\n",
      "epoch: 830 Test accuracy: 0.478\n",
      "F1 Score (Weighted): 0.47358793815836475\n",
      "epoch: 840 Test accuracy: 0.553\n",
      "F1 Score (Weighted): 0.5420556998224844\n",
      "epoch: 850 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.24338534148827728\n",
      "epoch: 860 Test accuracy: 0.4055\n",
      "F1 Score (Weighted): 0.3229952409959644\n",
      "epoch: 870 Test accuracy: 0.4415\n",
      "F1 Score (Weighted): 0.45694685086274694\n",
      "epoch: 880 Test accuracy: 0.5965\n",
      "F1 Score (Weighted): 0.5262809874401523\n",
      "epoch: 890 Test accuracy: 0.324\n",
      "F1 Score (Weighted): 0.32188844956838375\n",
      "epoch: 900 Test accuracy: 0.336\n",
      "F1 Score (Weighted): 0.25610053773609937\n",
      "epoch: 910 Test accuracy: 0.394\n",
      "F1 Score (Weighted): 0.3100818022328549\n",
      "epoch: 920 Test accuracy: 0.496\n",
      "F1 Score (Weighted): 0.4985756537404947\n",
      "epoch: 930 Test accuracy: 0.2955\n",
      "F1 Score (Weighted): 0.23657990488331818\n",
      "epoch: 940 Test accuracy: 0.3975\n",
      "F1 Score (Weighted): 0.31299689722776586\n",
      "epoch: 950 Test accuracy: 0.4145\n",
      "F1 Score (Weighted): 0.3388255733355077\n",
      "epoch: 960 Test accuracy: 0.479\n",
      "F1 Score (Weighted): 0.46617049924669895\n",
      "epoch: 970 Test accuracy: 0.524\n",
      "F1 Score (Weighted): 0.5200619645257513\n",
      "epoch: 980 Test accuracy: 0.421\n",
      "F1 Score (Weighted): 0.3929331369557853\n",
      "epoch: 990 Test accuracy: 0.4215\n",
      "F1 Score (Weighted): 0.3556825188395221\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_linear = MLP(sizes=[2, 10, 10, 3], activation_fn=linear,\n",
    "                activation_fn_derivative=linear_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_linear = mlp_rings_linear.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:01:20.731952Z",
     "start_time": "2024-04-03T21:01:20.669811Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "# This might involve looping through X_test_scaled and using your model's predict method\n",
    "predictions_rings_sigmoid = np.argmax(np.array([mlp_rings_sigmoid.propagate_forward(x.reshape(-1, 1))[0] for x in X_test_rings]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:01:21.473173Z",
     "start_time": "2024-04-03T21:01:21.470425Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.777\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy or other metrics\n",
    "accuracy_rings = np.mean(predictions_rings_sigmoid == y_test_rings)\n",
    "print(f'Test accuracy: {accuracy_rings}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:01:22.608618Z",
     "start_time": "2024-04-03T21:01:22.604415Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.7758968530554419\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 Score\n",
    "f1_weighted_rings = f1_score(y_test_rings, predictions_rings_sigmoid, average='weighted')\n",
    "\n",
    "print(f\"F1 Score (Weighted): {f1_weighted_rings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:01:24.657203Z",
     "start_time": "2024-04-03T21:01:24.631285Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "# This might involve looping through X_test_scaled and using your model's predict method\n",
    "predictions_rings_relu = np.argmax(np.array([mlp_rings_relu.propagate_forward(x.reshape(-1, 1))[0] for x in X_test_rings]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:01:25.377029Z",
     "start_time": "2024-04-03T21:01:25.374832Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.3845\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy or other metrics\n",
    "accuracy_rings = np.mean(predictions_rings_relu == y_test_rings)\n",
    "print(f'Test accuracy: {accuracy_rings}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:01:26.139835Z",
     "start_time": "2024-04-03T21:01:26.135983Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.21356482484651498\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 Score\n",
    "f1_weighted_rings = f1_score(y_test_rings, predictions_rings_relu, average='weighted')\n",
    "\n",
    "print(f\"F1 Score (Weighted): {f1_weighted_rings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### rings 5 regular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:24.131493Z",
     "start_time": "2024-04-03T21:03:24.129284Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scaler_X = DataScaler(\"standardization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:24.631111Z",
     "start_time": "2024-04-03T21:03:24.628743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "X1_train_rings = df_train_rings5_regular[['x']].values.reshape(-1, 1)\n",
    "X1_test_rings = df_test_rings5_regular[['x']].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:25.235965Z",
     "start_time": "2024-04-03T21:03:25.233670Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X2_train_rings = df_train_rings5_regular[['y']].values.reshape(-1, 1)\n",
    "X2_test_rings = df_test_rings5_regular[['y']].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:25.890136Z",
     "start_time": "2024-04-03T21:03:25.888079Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_rings = np.hstack((X1_train_rings, X2_train_rings))\n",
    "X_test_rings = np.hstack((X1_test_rings, X2_test_rings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:26.500420Z",
     "start_time": "2024-04-03T21:03:26.498362Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_rings_scaled = np.hstack((scaler_X.fit_transform(X1_train_rings), scaler_X.fit_transform(X2_train_rings)))\n",
    "X_test_rings_scaled = np.hstack((scaler_X.transform(X1_test_rings), scaler_X.transform(X2_test_rings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:34.847767Z",
     "start_time": "2024-04-03T21:03:34.845508Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_train_rings = df_train_rings5_regular['c'].values.reshape(-1, 1)\n",
    "y_test_rings = df_test_rings5_regular['c'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:35.341433Z",
     "start_time": "2024-04-03T21:03:35.338254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Encode the 'c' column into one-hot vectors for the training and test datasets\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded_rings = encoder.fit_transform(y_train_rings)\n",
    "y_test_encoded_rings = encoder.transform(y_test_rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:44.408833Z",
     "start_time": "2024-04-03T21:03:44.406393Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_rings = y_train_encoded_rings.shape[1] \n",
    "num_classes_rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:03:44.980840Z",
     "start_time": "2024-04-03T21:03:44.978316Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_data_rings = [\n",
    "    (X_train_rings[i].reshape(-1, 1), y_train_encoded_rings[i].reshape(-1, 1))\n",
    "    for i in range(len(X_train_rings))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:04:16.110818Z",
     "start_time": "2024-04-03T21:03:59.807349Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.3865\n",
      "F1 Score (Weighted): 0.327492427666276\n",
      "epoch: 10 Test accuracy: 0.517\n",
      "F1 Score (Weighted): 0.49566571246812774\n",
      "epoch: 20 Test accuracy: 0.645\n",
      "F1 Score (Weighted): 0.6342029991949544\n",
      "epoch: 30 Test accuracy: 0.6595\n",
      "F1 Score (Weighted): 0.6465113317170362\n",
      "epoch: 40 Test accuracy: 0.644\n",
      "F1 Score (Weighted): 0.6418488188416405\n",
      "epoch: 50 Test accuracy: 0.655\n",
      "F1 Score (Weighted): 0.65409953449881\n",
      "epoch: 60 Test accuracy: 0.654\n",
      "F1 Score (Weighted): 0.656715836580395\n",
      "epoch: 70 Test accuracy: 0.5905\n",
      "F1 Score (Weighted): 0.5835914714166471\n",
      "epoch: 80 Test accuracy: 0.657\n",
      "F1 Score (Weighted): 0.65422311954933\n",
      "epoch: 90 Test accuracy: 0.6075\n",
      "F1 Score (Weighted): 0.5795123141300352\n",
      "epoch: 100 Test accuracy: 0.6525\n",
      "F1 Score (Weighted): 0.6439482286786011\n",
      "epoch: 110 Test accuracy: 0.661\n",
      "F1 Score (Weighted): 0.657582159974674\n",
      "epoch: 120 Test accuracy: 0.5695\n",
      "F1 Score (Weighted): 0.5618587915211405\n",
      "epoch: 130 Test accuracy: 0.6555\n",
      "F1 Score (Weighted): 0.6541351381752766\n",
      "epoch: 140 Test accuracy: 0.664\n",
      "F1 Score (Weighted): 0.6566643346982435\n",
      "epoch: 150 Test accuracy: 0.6445\n",
      "F1 Score (Weighted): 0.6397982512817223\n",
      "epoch: 160 Test accuracy: 0.6765\n",
      "F1 Score (Weighted): 0.6702590737141333\n",
      "epoch: 170 Test accuracy: 0.676\n",
      "F1 Score (Weighted): 0.6730362138634272\n",
      "epoch: 180 Test accuracy: 0.637\n",
      "F1 Score (Weighted): 0.6155829151880967\n",
      "epoch: 190 Test accuracy: 0.6325\n",
      "F1 Score (Weighted): 0.6231402798985043\n",
      "epoch: 200 Test accuracy: 0.6235\n",
      "F1 Score (Weighted): 0.6045368423117418\n",
      "epoch: 210 Test accuracy: 0.6135\n",
      "F1 Score (Weighted): 0.608359768271694\n",
      "epoch: 220 Test accuracy: 0.663\n",
      "F1 Score (Weighted): 0.6584696095817641\n",
      "epoch: 230 Test accuracy: 0.6635\n",
      "F1 Score (Weighted): 0.664806590858038\n",
      "epoch: 240 Test accuracy: 0.7505\n",
      "F1 Score (Weighted): 0.7468993012468038\n",
      "epoch: 250 Test accuracy: 0.678\n",
      "F1 Score (Weighted): 0.6703355880894386\n",
      "epoch: 260 Test accuracy: 0.7345\n",
      "F1 Score (Weighted): 0.7332644146517204\n",
      "epoch: 270 Test accuracy: 0.6495\n",
      "F1 Score (Weighted): 0.6369880483804038\n",
      "epoch: 280 Test accuracy: 0.673\n",
      "F1 Score (Weighted): 0.6764482649078243\n",
      "epoch: 290 Test accuracy: 0.6975\n",
      "F1 Score (Weighted): 0.694047681065297\n",
      "epoch: 300 Test accuracy: 0.651\n",
      "F1 Score (Weighted): 0.6414059814673047\n",
      "epoch: 310 Test accuracy: 0.7175\n",
      "F1 Score (Weighted): 0.7185402587531036\n",
      "epoch: 320 Test accuracy: 0.73\n",
      "F1 Score (Weighted): 0.726636716032479\n",
      "epoch: 330 Test accuracy: 0.6435\n",
      "F1 Score (Weighted): 0.6267986820503237\n",
      "epoch: 340 Test accuracy: 0.689\n",
      "F1 Score (Weighted): 0.684673399568839\n",
      "epoch: 350 Test accuracy: 0.732\n",
      "F1 Score (Weighted): 0.7299266931488033\n",
      "epoch: 360 Test accuracy: 0.694\n",
      "F1 Score (Weighted): 0.6770026165566229\n",
      "epoch: 370 Test accuracy: 0.7565\n",
      "F1 Score (Weighted): 0.7552693634940021\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_sigmoid_2 = MLP(sizes=[2, 10, 10, 5], activation_fn=sigmoid,\n",
    "                activation_fn_derivative=sigmoid_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_sigmoid_2 = mlp_rings_sigmoid_2.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:00.533546Z",
     "start_time": "2024-04-03T21:04:32.923734Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.149\n",
      "F1 Score (Weighted): 0.1308927361605541\n",
      "epoch: 10 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 20 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 30 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 40 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 50 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 60 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 70 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 80 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 90 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 100 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 110 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 120 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 130 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 140 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 150 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 160 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 170 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 180 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 190 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 200 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 210 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 220 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 230 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 240 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 250 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 260 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 270 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 280 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 290 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 300 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 310 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 320 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 330 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 340 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 350 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 360 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 370 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 380 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 390 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 400 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 410 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 420 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 430 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 440 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 450 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 460 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 470 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 480 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 490 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 500 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 510 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 520 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 530 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 540 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 550 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 560 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 570 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 580 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 590 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 600 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 610 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 620 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 630 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 640 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 650 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 660 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 670 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 680 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 690 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 700 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 710 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 720 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 730 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 740 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 750 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 760 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 770 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 780 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 790 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 800 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 810 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 820 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 830 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 840 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 850 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 860 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 870 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 880 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 890 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 900 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 910 Test accuracy: 0.1255\n",
      "F1 Score (Weighted): 0.027988005330964013\n",
      "epoch: 920 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 930 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 940 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 950 Test accuracy: 0.054\n",
      "F1 Score (Weighted): 0.005533206831119544\n",
      "epoch: 960 Test accuracy: 0.346\n",
      "F1 Score (Weighted): 0.17788410104011884\n",
      "epoch: 970 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n",
      "epoch: 980 Test accuracy: 0.1545\n",
      "F1 Score (Weighted): 0.04135166738847986\n",
      "epoch: 990 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.15515151515151515\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_relu_2 = MLP(sizes=[2, 10, 10, 5], activation_fn=relu,\n",
    "                activation_fn_derivative=relu_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_relu_2 = mlp_rings_relu_2.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:24.669664Z",
     "start_time": "2024-04-03T21:05:00.534390Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.261\n",
      "F1 Score (Weighted): 0.22648686450496275\n",
      "epoch: 10 Test accuracy: 0.3175\n",
      "F1 Score (Weighted): 0.23466942598763205\n",
      "epoch: 20 Test accuracy: 0.33\n",
      "F1 Score (Weighted): 0.33966421076335834\n",
      "epoch: 30 Test accuracy: 0.31\n",
      "F1 Score (Weighted): 0.2934706126847865\n",
      "epoch: 40 Test accuracy: 0.365\n",
      "F1 Score (Weighted): 0.33309472642702576\n",
      "epoch: 50 Test accuracy: 0.4025\n",
      "F1 Score (Weighted): 0.37989024567877194\n",
      "epoch: 60 Test accuracy: 0.4415\n",
      "F1 Score (Weighted): 0.39839079442031605\n",
      "epoch: 70 Test accuracy: 0.3435\n",
      "F1 Score (Weighted): 0.27763011803899484\n",
      "epoch: 80 Test accuracy: 0.43\n",
      "F1 Score (Weighted): 0.40474476042420854\n",
      "epoch: 90 Test accuracy: 0.3255\n",
      "F1 Score (Weighted): 0.23872326447573655\n",
      "epoch: 100 Test accuracy: 0.4055\n",
      "F1 Score (Weighted): 0.36819335784060486\n",
      "epoch: 110 Test accuracy: 0.359\n",
      "F1 Score (Weighted): 0.34922718941109654\n",
      "epoch: 120 Test accuracy: 0.318\n",
      "F1 Score (Weighted): 0.2763762624125083\n",
      "epoch: 130 Test accuracy: 0.4465\n",
      "F1 Score (Weighted): 0.3979571951831978\n",
      "epoch: 140 Test accuracy: 0.3145\n",
      "F1 Score (Weighted): 0.23208265767519923\n",
      "epoch: 150 Test accuracy: 0.337\n",
      "F1 Score (Weighted): 0.28440217879406243\n",
      "epoch: 160 Test accuracy: 0.2615\n",
      "F1 Score (Weighted): 0.22022240580639307\n",
      "epoch: 170 Test accuracy: 0.3395\n",
      "F1 Score (Weighted): 0.33165102498277926\n",
      "epoch: 180 Test accuracy: 0.3435\n",
      "F1 Score (Weighted): 0.2980953119842805\n",
      "epoch: 190 Test accuracy: 0.3965\n",
      "F1 Score (Weighted): 0.3770874519115215\n",
      "epoch: 200 Test accuracy: 0.396\n",
      "F1 Score (Weighted): 0.3511915812175396\n",
      "epoch: 210 Test accuracy: 0.3835\n",
      "F1 Score (Weighted): 0.3813017953719945\n",
      "epoch: 220 Test accuracy: 0.4545\n",
      "F1 Score (Weighted): 0.3753565976261597\n",
      "epoch: 230 Test accuracy: 0.3925\n",
      "F1 Score (Weighted): 0.38657487975161636\n",
      "epoch: 240 Test accuracy: 0.321\n",
      "F1 Score (Weighted): 0.3118141029478307\n",
      "epoch: 250 Test accuracy: 0.313\n",
      "F1 Score (Weighted): 0.26704459048789625\n",
      "epoch: 260 Test accuracy: 0.3665\n",
      "F1 Score (Weighted): 0.3425505441285047\n",
      "epoch: 270 Test accuracy: 0.4215\n",
      "F1 Score (Weighted): 0.38609431824745566\n",
      "epoch: 280 Test accuracy: 0.31\n",
      "F1 Score (Weighted): 0.24147922706963793\n",
      "epoch: 290 Test accuracy: 0.2955\n",
      "F1 Score (Weighted): 0.2626678074564021\n",
      "epoch: 300 Test accuracy: 0.36\n",
      "F1 Score (Weighted): 0.2878350593585514\n",
      "epoch: 310 Test accuracy: 0.3575\n",
      "F1 Score (Weighted): 0.3372578077735035\n",
      "epoch: 320 Test accuracy: 0.3635\n",
      "F1 Score (Weighted): 0.3683054610114211\n",
      "epoch: 330 Test accuracy: 0.337\n",
      "F1 Score (Weighted): 0.27164015858990137\n",
      "epoch: 340 Test accuracy: 0.398\n",
      "F1 Score (Weighted): 0.3866708675320167\n",
      "epoch: 350 Test accuracy: 0.2935\n",
      "F1 Score (Weighted): 0.2903376739256388\n",
      "epoch: 360 Test accuracy: 0.403\n",
      "F1 Score (Weighted): 0.31323358442025534\n",
      "epoch: 370 Test accuracy: 0.352\n",
      "F1 Score (Weighted): 0.31305758460297517\n",
      "epoch: 380 Test accuracy: 0.3735\n",
      "F1 Score (Weighted): 0.35329094637487873\n",
      "epoch: 390 Test accuracy: 0.3175\n",
      "F1 Score (Weighted): 0.22865782365404233\n",
      "epoch: 400 Test accuracy: 0.3475\n",
      "F1 Score (Weighted): 0.2858626485123828\n",
      "epoch: 410 Test accuracy: 0.3395\n",
      "F1 Score (Weighted): 0.2796327512483319\n",
      "epoch: 420 Test accuracy: 0.3295\n",
      "F1 Score (Weighted): 0.22992443637305082\n",
      "epoch: 430 Test accuracy: 0.362\n",
      "F1 Score (Weighted): 0.3369096394639327\n",
      "epoch: 440 Test accuracy: 0.495\n",
      "F1 Score (Weighted): 0.471617094598531\n",
      "epoch: 450 Test accuracy: 0.2635\n",
      "F1 Score (Weighted): 0.15071612449186553\n",
      "epoch: 460 Test accuracy: 0.36\n",
      "F1 Score (Weighted): 0.36705451771378483\n",
      "epoch: 470 Test accuracy: 0.443\n",
      "F1 Score (Weighted): 0.40213770387480613\n",
      "epoch: 480 Test accuracy: 0.333\n",
      "F1 Score (Weighted): 0.3156133309649965\n",
      "epoch: 490 Test accuracy: 0.4045\n",
      "F1 Score (Weighted): 0.34018369922500735\n",
      "epoch: 500 Test accuracy: 0.4915\n",
      "F1 Score (Weighted): 0.4323841689363544\n",
      "epoch: 510 Test accuracy: 0.3325\n",
      "F1 Score (Weighted): 0.3279596496056818\n",
      "epoch: 520 Test accuracy: 0.4285\n",
      "F1 Score (Weighted): 0.4170199617361495\n",
      "epoch: 530 Test accuracy: 0.441\n",
      "F1 Score (Weighted): 0.4254352954558547\n",
      "epoch: 540 Test accuracy: 0.3455\n",
      "F1 Score (Weighted): 0.3173283074670194\n",
      "epoch: 550 Test accuracy: 0.285\n",
      "F1 Score (Weighted): 0.2590287377397932\n",
      "epoch: 560 Test accuracy: 0.412\n",
      "F1 Score (Weighted): 0.3376705649618161\n",
      "epoch: 570 Test accuracy: 0.384\n",
      "F1 Score (Weighted): 0.33475252901430247\n",
      "epoch: 580 Test accuracy: 0.3685\n",
      "F1 Score (Weighted): 0.3446329214729658\n",
      "epoch: 590 Test accuracy: 0.474\n",
      "F1 Score (Weighted): 0.46486639539596253\n",
      "epoch: 600 Test accuracy: 0.4255\n",
      "F1 Score (Weighted): 0.398870149743071\n",
      "epoch: 610 Test accuracy: 0.3865\n",
      "F1 Score (Weighted): 0.3317440137658457\n",
      "epoch: 620 Test accuracy: 0.434\n",
      "F1 Score (Weighted): 0.42279669754556515\n",
      "epoch: 630 Test accuracy: 0.343\n",
      "F1 Score (Weighted): 0.2844247486055649\n",
      "epoch: 640 Test accuracy: 0.3415\n",
      "F1 Score (Weighted): 0.31760050578610444\n",
      "epoch: 650 Test accuracy: 0.429\n",
      "F1 Score (Weighted): 0.4166131903748217\n",
      "epoch: 660 Test accuracy: 0.413\n",
      "F1 Score (Weighted): 0.38863902142666906\n",
      "epoch: 670 Test accuracy: 0.2865\n",
      "F1 Score (Weighted): 0.2038529619497041\n",
      "epoch: 680 Test accuracy: 0.384\n",
      "F1 Score (Weighted): 0.3320310573412465\n",
      "epoch: 690 Test accuracy: 0.406\n",
      "F1 Score (Weighted): 0.3817294782967437\n",
      "epoch: 700 Test accuracy: 0.409\n",
      "F1 Score (Weighted): 0.3281695933247344\n",
      "epoch: 710 Test accuracy: 0.332\n",
      "F1 Score (Weighted): 0.3193080068169165\n",
      "epoch: 720 Test accuracy: 0.314\n",
      "F1 Score (Weighted): 0.2317319561098721\n",
      "epoch: 730 Test accuracy: 0.375\n",
      "F1 Score (Weighted): 0.35031618019060545\n",
      "epoch: 740 Test accuracy: 0.351\n",
      "F1 Score (Weighted): 0.2981349968262787\n",
      "epoch: 750 Test accuracy: 0.4095\n",
      "F1 Score (Weighted): 0.33120027653537615\n",
      "epoch: 760 Test accuracy: 0.4185\n",
      "F1 Score (Weighted): 0.34753963859358133\n",
      "epoch: 770 Test accuracy: 0.3495\n",
      "F1 Score (Weighted): 0.3412824123855367\n",
      "epoch: 780 Test accuracy: 0.4195\n",
      "F1 Score (Weighted): 0.4074154746437627\n",
      "epoch: 790 Test accuracy: 0.298\n",
      "F1 Score (Weighted): 0.23385652828454395\n",
      "epoch: 800 Test accuracy: 0.4\n",
      "F1 Score (Weighted): 0.3170008971881031\n",
      "epoch: 810 Test accuracy: 0.3975\n",
      "F1 Score (Weighted): 0.3699951199762536\n",
      "epoch: 820 Test accuracy: 0.477\n",
      "F1 Score (Weighted): 0.4545082287492359\n",
      "epoch: 830 Test accuracy: 0.286\n",
      "F1 Score (Weighted): 0.27203352316624146\n",
      "epoch: 840 Test accuracy: 0.4415\n",
      "F1 Score (Weighted): 0.3764804387359569\n",
      "epoch: 850 Test accuracy: 0.3685\n",
      "F1 Score (Weighted): 0.31729696664364027\n",
      "epoch: 860 Test accuracy: 0.247\n",
      "F1 Score (Weighted): 0.1502199824031053\n",
      "epoch: 870 Test accuracy: 0.363\n",
      "F1 Score (Weighted): 0.3411501831122464\n",
      "epoch: 880 Test accuracy: 0.4085\n",
      "F1 Score (Weighted): 0.3815202887231397\n",
      "epoch: 890 Test accuracy: 0.3575\n",
      "F1 Score (Weighted): 0.2704962277998216\n",
      "epoch: 900 Test accuracy: 0.428\n",
      "F1 Score (Weighted): 0.41764686931813927\n",
      "epoch: 910 Test accuracy: 0.411\n",
      "F1 Score (Weighted): 0.39836340386313024\n",
      "epoch: 920 Test accuracy: 0.3225\n",
      "F1 Score (Weighted): 0.2921822982153784\n",
      "epoch: 930 Test accuracy: 0.4125\n",
      "F1 Score (Weighted): 0.35795570962961754\n",
      "epoch: 940 Test accuracy: 0.3785\n",
      "F1 Score (Weighted): 0.3221575614508574\n",
      "epoch: 950 Test accuracy: 0.2355\n",
      "F1 Score (Weighted): 0.12653679574570878\n",
      "epoch: 960 Test accuracy: 0.4415\n",
      "F1 Score (Weighted): 0.37439231814052615\n",
      "epoch: 970 Test accuracy: 0.356\n",
      "F1 Score (Weighted): 0.3344637874791373\n",
      "epoch: 980 Test accuracy: 0.249\n",
      "F1 Score (Weighted): 0.22091073473599226\n",
      "epoch: 990 Test accuracy: 0.385\n",
      "F1 Score (Weighted): 0.3375399399071878\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_tanh_2 = MLP(sizes=[2, 10, 10, 5], activation_fn=tanh,\n",
    "                activation_fn_derivative=tanh_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_tanh_2 = mlp_rings_tanh_2.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.864936Z",
     "start_time": "2024-04-03T21:05:24.670512Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test accuracy: 0.383\n",
      "F1 Score (Weighted): 0.28441312889004655\n",
      "epoch: 10 Test accuracy: 0.3195\n",
      "F1 Score (Weighted): 0.2386646829176723\n",
      "epoch: 20 Test accuracy: 0.175\n",
      "F1 Score (Weighted): 0.1876981485446615\n",
      "epoch: 30 Test accuracy: 0.2565\n",
      "F1 Score (Weighted): 0.1627732645699262\n",
      "epoch: 40 Test accuracy: 0.1855\n",
      "F1 Score (Weighted): 0.2238263609977174\n",
      "epoch: 50 Test accuracy: 0.261\n",
      "F1 Score (Weighted): 0.18086192807268628\n",
      "epoch: 60 Test accuracy: 0.265\n",
      "F1 Score (Weighted): 0.23549470427921562\n",
      "epoch: 70 Test accuracy: 0.411\n",
      "F1 Score (Weighted): 0.37807308312386\n",
      "epoch: 80 Test accuracy: 0.32\n",
      "F1 Score (Weighted): 0.26578508261490663\n",
      "epoch: 90 Test accuracy: 0.3995\n",
      "F1 Score (Weighted): 0.37221949028691204\n",
      "epoch: 100 Test accuracy: 0.394\n",
      "F1 Score (Weighted): 0.3431656175368678\n",
      "epoch: 110 Test accuracy: 0.399\n",
      "F1 Score (Weighted): 0.38835241611867277\n",
      "epoch: 120 Test accuracy: 0.216\n",
      "F1 Score (Weighted): 0.22181026371092075\n",
      "epoch: 130 Test accuracy: 0.228\n",
      "F1 Score (Weighted): 0.24038706563657708\n",
      "epoch: 140 Test accuracy: 0.1505\n",
      "F1 Score (Weighted): 0.09728582605863903\n",
      "epoch: 150 Test accuracy: 0.1715\n",
      "F1 Score (Weighted): 0.18615674220783363\n",
      "epoch: 160 Test accuracy: 0.061\n",
      "F1 Score (Weighted): 0.031597200782217755\n",
      "epoch: 170 Test accuracy: 0.195\n",
      "F1 Score (Weighted): 0.20671463495155118\n",
      "epoch: 180 Test accuracy: 0.37\n",
      "F1 Score (Weighted): 0.3364225429046639\n",
      "epoch: 190 Test accuracy: 0.4165\n",
      "F1 Score (Weighted): 0.38476870777438665\n",
      "epoch: 200 Test accuracy: 0.439\n",
      "F1 Score (Weighted): 0.41537554481012134\n",
      "epoch: 210 Test accuracy: 0.323\n",
      "F1 Score (Weighted): 0.2482020973691574\n",
      "epoch: 220 Test accuracy: 0.475\n",
      "F1 Score (Weighted): 0.41783647529023277\n",
      "epoch: 230 Test accuracy: 0.2645\n",
      "F1 Score (Weighted): 0.2750527809328848\n",
      "epoch: 240 Test accuracy: 0.2095\n",
      "F1 Score (Weighted): 0.1824813026680115\n",
      "epoch: 250 Test accuracy: 0.249\n",
      "F1 Score (Weighted): 0.2607936677675954\n",
      "epoch: 260 Test accuracy: 0.3555\n",
      "F1 Score (Weighted): 0.3361471320206774\n",
      "epoch: 270 Test accuracy: 0.3895\n",
      "F1 Score (Weighted): 0.347948488765922\n",
      "epoch: 280 Test accuracy: 0.237\n",
      "F1 Score (Weighted): 0.1757079534276873\n",
      "epoch: 290 Test accuracy: 0.2775\n",
      "F1 Score (Weighted): 0.23637439998187887\n",
      "epoch: 300 Test accuracy: 0.269\n",
      "F1 Score (Weighted): 0.2211776287014543\n",
      "epoch: 310 Test accuracy: 0.284\n",
      "F1 Score (Weighted): 0.3004421888436\n",
      "epoch: 320 Test accuracy: 0.2915\n",
      "F1 Score (Weighted): 0.24209049127109725\n",
      "epoch: 330 Test accuracy: 0.21\n",
      "F1 Score (Weighted): 0.156026866556186\n",
      "epoch: 340 Test accuracy: 0.2975\n",
      "F1 Score (Weighted): 0.2503851549148413\n",
      "epoch: 350 Test accuracy: 0.3155\n",
      "F1 Score (Weighted): 0.28052600715714654\n",
      "epoch: 360 Test accuracy: 0.29\n",
      "F1 Score (Weighted): 0.23717432079951917\n",
      "epoch: 370 Test accuracy: 0.2435\n",
      "F1 Score (Weighted): 0.24217154152442133\n",
      "epoch: 380 Test accuracy: 0.2995\n",
      "F1 Score (Weighted): 0.3114114297119935\n",
      "epoch: 390 Test accuracy: 0.117\n",
      "F1 Score (Weighted): 0.10349603112213578\n",
      "epoch: 400 Test accuracy: 0.2375\n",
      "F1 Score (Weighted): 0.20137021072955355\n",
      "epoch: 410 Test accuracy: 0.3085\n",
      "F1 Score (Weighted): 0.31812710473652334\n",
      "epoch: 420 Test accuracy: 0.3365\n",
      "F1 Score (Weighted): 0.30838099924896895\n",
      "epoch: 430 Test accuracy: 0.299\n",
      "F1 Score (Weighted): 0.19819006602021869\n",
      "epoch: 440 Test accuracy: 0.209\n",
      "F1 Score (Weighted): 0.17178215535126728\n",
      "epoch: 450 Test accuracy: 0.332\n",
      "F1 Score (Weighted): 0.2724810781620165\n",
      "epoch: 460 Test accuracy: 0.321\n",
      "F1 Score (Weighted): 0.22565565980103405\n",
      "epoch: 470 Test accuracy: 0.2965\n",
      "F1 Score (Weighted): 0.2515750511354026\n",
      "epoch: 480 Test accuracy: 0.345\n",
      "F1 Score (Weighted): 0.30414017771630747\n",
      "epoch: 490 Test accuracy: 0.265\n",
      "F1 Score (Weighted): 0.26187448764019844\n",
      "epoch: 500 Test accuracy: 0.338\n",
      "F1 Score (Weighted): 0.30435188688823755\n",
      "epoch: 510 Test accuracy: 0.4075\n",
      "F1 Score (Weighted): 0.32751442158255406\n",
      "epoch: 520 Test accuracy: 0.3335\n",
      "F1 Score (Weighted): 0.3678146090573306\n",
      "epoch: 530 Test accuracy: 0.3485\n",
      "F1 Score (Weighted): 0.32003251737687755\n",
      "epoch: 540 Test accuracy: 0.15\n",
      "F1 Score (Weighted): 0.1576884397852075\n",
      "epoch: 550 Test accuracy: 0.4545\n",
      "F1 Score (Weighted): 0.427433985851862\n",
      "epoch: 560 Test accuracy: 0.386\n",
      "F1 Score (Weighted): 0.3301624504980617\n",
      "epoch: 570 Test accuracy: 0.3325\n",
      "F1 Score (Weighted): 0.2653923142656025\n",
      "epoch: 580 Test accuracy: 0.257\n",
      "F1 Score (Weighted): 0.18541392195177517\n",
      "epoch: 590 Test accuracy: 0.1665\n",
      "F1 Score (Weighted): 0.08560398648067212\n",
      "epoch: 600 Test accuracy: 0.243\n",
      "F1 Score (Weighted): 0.1571600860575635\n",
      "epoch: 610 Test accuracy: 0.265\n",
      "F1 Score (Weighted): 0.2133376471796201\n",
      "epoch: 620 Test accuracy: 0.3595\n",
      "F1 Score (Weighted): 0.33821398830815363\n",
      "epoch: 630 Test accuracy: 0.2285\n",
      "F1 Score (Weighted): 0.25419123635021257\n",
      "epoch: 640 Test accuracy: 0.238\n",
      "F1 Score (Weighted): 0.26107135158081357\n",
      "epoch: 650 Test accuracy: 0.209\n",
      "F1 Score (Weighted): 0.165859766014657\n",
      "epoch: 660 Test accuracy: 0.206\n",
      "F1 Score (Weighted): 0.16805236327942044\n",
      "epoch: 670 Test accuracy: 0.202\n",
      "F1 Score (Weighted): 0.15101277848385364\n",
      "epoch: 680 Test accuracy: 0.284\n",
      "F1 Score (Weighted): 0.21784976517616678\n",
      "epoch: 690 Test accuracy: 0.2405\n",
      "F1 Score (Weighted): 0.1998420960407737\n",
      "epoch: 700 Test accuracy: 0.222\n",
      "F1 Score (Weighted): 0.2302144194288553\n",
      "epoch: 710 Test accuracy: 0.2655\n",
      "F1 Score (Weighted): 0.2284247092450203\n",
      "epoch: 720 Test accuracy: 0.2955\n",
      "F1 Score (Weighted): 0.2699480235135503\n",
      "epoch: 730 Test accuracy: 0.279\n",
      "F1 Score (Weighted): 0.20714203421979135\n",
      "epoch: 740 Test accuracy: 0.3165\n",
      "F1 Score (Weighted): 0.2969980666244507\n",
      "epoch: 750 Test accuracy: 0.2965\n",
      "F1 Score (Weighted): 0.2061596551483411\n",
      "epoch: 760 Test accuracy: 0.246\n",
      "F1 Score (Weighted): 0.23964943380566597\n",
      "epoch: 770 Test accuracy: 0.347\n",
      "F1 Score (Weighted): 0.2814992943454708\n",
      "epoch: 780 Test accuracy: 0.1785\n",
      "F1 Score (Weighted): 0.13287203936516487\n",
      "epoch: 790 Test accuracy: 0.153\n",
      "F1 Score (Weighted): 0.12427358705487496\n",
      "epoch: 800 Test accuracy: 0.328\n",
      "F1 Score (Weighted): 0.3149569798733992\n",
      "epoch: 810 Test accuracy: 0.3155\n",
      "F1 Score (Weighted): 0.2283703246782305\n",
      "epoch: 820 Test accuracy: 0.323\n",
      "F1 Score (Weighted): 0.3142230011790383\n",
      "epoch: 830 Test accuracy: 0.1755\n",
      "F1 Score (Weighted): 0.16893720133335777\n",
      "epoch: 840 Test accuracy: 0.3495\n",
      "F1 Score (Weighted): 0.28824639944262115\n",
      "epoch: 850 Test accuracy: 0.3235\n",
      "F1 Score (Weighted): 0.3081794176057023\n",
      "epoch: 860 Test accuracy: 0.3025\n",
      "F1 Score (Weighted): 0.2800035736337395\n",
      "epoch: 870 Test accuracy: 0.4085\n",
      "F1 Score (Weighted): 0.3482747467042185\n",
      "epoch: 880 Test accuracy: 0.3055\n",
      "F1 Score (Weighted): 0.24169604609181977\n",
      "epoch: 890 Test accuracy: 0.3405\n",
      "F1 Score (Weighted): 0.260729923966205\n",
      "epoch: 900 Test accuracy: 0.326\n",
      "F1 Score (Weighted): 0.29923419404387575\n",
      "epoch: 910 Test accuracy: 0.2605\n",
      "F1 Score (Weighted): 0.1812231994129338\n",
      "epoch: 920 Test accuracy: 0.245\n",
      "F1 Score (Weighted): 0.2111929095053461\n",
      "epoch: 930 Test accuracy: 0.3255\n",
      "F1 Score (Weighted): 0.2484251963730718\n",
      "epoch: 940 Test accuracy: 0.3205\n",
      "F1 Score (Weighted): 0.2981734448561316\n",
      "epoch: 950 Test accuracy: 0.244\n",
      "F1 Score (Weighted): 0.21536171694078174\n",
      "epoch: 960 Test accuracy: 0.407\n",
      "F1 Score (Weighted): 0.3475931431189824\n",
      "epoch: 970 Test accuracy: 0.3575\n",
      "F1 Score (Weighted): 0.3331703846627362\n",
      "epoch: 980 Test accuracy: 0.178\n",
      "F1 Score (Weighted): 0.0949326978321771\n",
      "epoch: 990 Test accuracy: 0.1805\n",
      "F1 Score (Weighted): 0.15817849787093666\n"
     ]
    }
   ],
   "source": [
    "mlp_rings_linear_2 = MLP(sizes=[2, 10, 10, 5], activation_fn=linear,\n",
    "                activation_fn_derivative=linear_derivative)  # Example layer setup\n",
    "\n",
    "# Train the MLP using your training data\n",
    "\n",
    "f1_linear_2 = mlp_rings_linear_2.train(training_data=training_data_rings, epochs=1000, learn_rate=0.01, batch_size=64, X_val=X_test_rings,\n",
    "                y_val=y_test_rings, visual_interval=10, target=0.75, decay_rate=0.01, adaptive_learn_rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.924178Z",
     "start_time": "2024-04-03T21:05:45.865479Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "# This might involve looping through X_test_scaled and using your model's predict method\n",
    "predictions_rings_sigmoid = np.argmax(np.array([mlp_rings_sigmoid_2.propagate_forward(x.reshape(-1, 1))[0] for x in X_test_rings]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.927046Z",
     "start_time": "2024-04-03T21:05:45.925277Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7565\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy or other metrics\n",
    "accuracy_rings = np.mean(predictions_rings_sigmoid == y_test_rings)\n",
    "print(f'Test accuracy: {accuracy_rings}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.930287Z",
     "start_time": "2024-04-03T21:05:45.927611Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.7552693634940021\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 Score\n",
    "f1_weighted_rings = f1_score(y_test_rings, predictions_rings_sigmoid, average='weighted')\n",
    "\n",
    "print(f\"F1 Score (Weighted): {f1_weighted_rings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.950290Z",
     "start_time": "2024-04-03T21:05:45.930740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "# This might involve looping through X_test_scaled and using your model's predict method\n",
    "predictions_rings_relu = np.argmax(np.array([mlp_rings_relu_2.propagate_forward(x.reshape(-1, 1))[0] for x in X_test_rings]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.952582Z",
     "start_time": "2024-04-03T21:05:45.950867Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.054\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy or other metrics\n",
    "accuracy_rings = np.mean(predictions_rings_relu == y_test_rings)\n",
    "print(f'Test accuracy: {accuracy_rings}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T21:05:45.956187Z",
     "start_time": "2024-04-03T21:05:45.953183Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.005533206831119544\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 Score\n",
    "f1_weighted_rings = f1_score(y_test_rings, predictions_rings_relu, average='weighted')\n",
    "\n",
    "print(f\"F1 Score (Weighted): {f1_weighted_rings}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
