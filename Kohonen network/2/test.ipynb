{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import get_cmap\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "class KohonenNetwork:\n",
    "    def __init__(self, M, N, input_dim, initial_sigma=1.0, sigma_decay=1.0, init_lr=0.1, decay_rate=1, neighborhood_function='gaussian'):\n",
    "        self.M, self.N, self.input_dim = M, N, input_dim\n",
    "        self.initial_sigma, self.sigma_decay = initial_sigma, sigma_decay\n",
    "        self.init_lr, self.decay_rate = init_lr, decay_rate\n",
    "        self.neighborhood_function = neighborhood_function\n",
    "        self.weights = np.random.rand(M, N, input_dim)\n",
    "        self.bmu_cluster_map = np.zeros((M, N), dtype=int)\n",
    "\n",
    "    def load_mnist_data(self):\n",
    "        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "        X = X / 255.0\n",
    "        return X, y.astype(int)\n",
    "\n",
    "    def train(self, input_data, labels, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            sigma = self.initial_sigma * np.exp(-epoch / self.decay_rate) * self.sigma_decay\n",
    "            learning_rate = self.init_lr * np.exp(-epoch / self.decay_rate)\n",
    "            idx = np.random.randint(len(input_data))\n",
    "            data_sample = input_data[idx]\n",
    "            label_sample = labels[idx]\n",
    "            bmu = self._find_bmu_and_update_weights(data_sample, sigma, learning_rate)\n",
    "            self.bmu_cluster_map[bmu] = label_sample\n",
    "\n",
    "    def create_labels_map(self, input_data, labels):\n",
    "        self.labels_map = np.zeros((self.M, self.N, 10))\n",
    "        self.bmu_cluster_map = np.zeros((self.M, self.N), dtype=int)\n",
    "\n",
    "        for i, data in enumerate(input_data):\n",
    "            bmu = self._find_bmu(data)\n",
    "            self.bmu_cluster_map[bmu] = labels[i]\n",
    "            self.labels_map[bmu][labels[i]] += 1\n",
    "\n",
    "        return self.labels_map\n",
    "\n",
    "    def plot_labels_map(self, labels_map, title):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(self.M):\n",
    "            for j in range(self.N):\n",
    "                color = labels_map[i, j] / 10.0\n",
    "                plt.plot([j+0.5], [i+0.5], 's', color=plt.cm.hsv(color), markersize=12)\n",
    "        plt.xlim([0, self.M])\n",
    "        plt.ylim([0, self.N])\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def accuracy(self, data, labels):\n",
    "        correct = 0\n",
    "        total = len(data)\n",
    "        \n",
    "        if total == 0:\n",
    "            return 0\n",
    "\n",
    "        for sample, label in zip(data, labels):\n",
    "            bmu = self._find_bmu_and_update_weights(sample, None, None)\n",
    "            if self.bmu_cluster_map[bmu] == label:\n",
    "                correct += 1\n",
    "\n",
    "        return 100 * correct / total\n",
    "\n",
    "\n",
    "\n",
    "    def _neighborhood_function(self, distance, sigma):\n",
    "        # Funkcja sąsiedztwa, która oblicza wpływ odległości na aktualizację wag.\n",
    "        if self.neighborhood_function == 'gaussian':\n",
    "            sigma = max(sigma, 1e-10)  # add a small constant to prevent division by zero\n",
    "            distance = np.clip(distance, -709, 709)  # limit the range of the input to prevent overflow\n",
    "            return np.exp(-distance**2 / (2 * sigma**2))\n",
    "        elif self.neighborhood_function == 'mexican_hat':\n",
    "            return (1 - (distance**2 / sigma**2)) * np.exp(-distance**2 / (2 * sigma**2))\n",
    "        else:\n",
    "            raise ValueError(f\"Nieznana funkcja sąsiedztwa: {self.neighborhood_function}\")\n",
    "\n",
    "\n",
    "\n",
    "    def _find_bmu_and_update_weights(self, sample, sigma, lr):\n",
    "        # Znalezienie BMU, aktualizacja wag i zwrócenie BMU.\n",
    "        distances = np.sqrt((self.weights[..., 0] - sample[0])**2 + 3/4 * (self.weights[..., 1] - sample[1])**2)  # hexagonal distance\n",
    "        bmu = np.unravel_index(np.argmin(distances), distances.shape)\n",
    "        \n",
    "        if sigma and lr:\n",
    "            x, y = np.ogrid[0:self.M, 0:self.N]\n",
    "            distance = np.sqrt((x - bmu[0])**2 + 3/4 * (y - bmu[1])**2)  # hexagonal distance\n",
    "            influence = self._neighborhood_function(distance, sigma)\n",
    "            self.weights += lr * influence[..., np.newaxis] * (sample - self.weights)\n",
    "        \n",
    "        return bmu\n",
    "\n",
    "    \n",
    "    def assign_clusters(self, input_data):\n",
    "        # Mapowanie klastrów na podstawie danych wejściowych.\n",
    "        cluster_stats = defaultdict(list)\n",
    "\n",
    "        for i, data_sample in enumerate(input_data):\n",
    "            # Wyszukujemy BMU, przy czym nie aktualizujemy wag\n",
    "            best_matching_unit = self._find_bmu_and_update_weights(data_sample, None, None)\n",
    "            self.bmu_cluster_map[best_matching_unit] = i\n",
    "\n",
    "\n",
    "\n",
    "    def display_clustered_data(self, input_data, neuron_positions=True, view_data=True):\n",
    "        # Wizualizacja sklastrowanych danych wejściowych.\n",
    "        assigned_clusters = np.array([self.bmu_cluster_map[self._find_bmu_and_update_weights(sample, None, None)] for sample in input_data])\n",
    "        distinct_clusters = np.unique(assigned_clusters)\n",
    "        color_map = plt.cm.get_cmap('viridis', len(distinct_clusters))\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d' if input_data.shape[1] == 3 else None)\n",
    "        if view_data:\n",
    "            # Wyświetlanie danych wejściowych sklastrowanych\n",
    "            for i, cluster in enumerate(distinct_clusters):\n",
    "                cluster_mask = assigned_clusters == cluster\n",
    "                if input_data.shape[1] == 3:\n",
    "                    ax.scatter(input_data[cluster_mask, 0], input_data[cluster_mask, 1], input_data[cluster_mask, 2], color=color_map(i), edgecolors='k', s=50, label=f'Klaster {i}')  # Use i for cluster number\n",
    "                else:\n",
    "                    ax.scatter(input_data[cluster_mask, 0], input_data[cluster_mask, 1], color=color_map(i), edgecolors='k', s=50, label=f'Klaster {i}')  # Use i for cluster number\n",
    "\n",
    "        if neuron_positions:\n",
    "            # Dodanie pozycji neuronów\n",
    "            neuron_positions = np.array([self.weights[i, j, :] for i in range(self.M) for j in range(self.N)])\n",
    "            if input_data.shape[1] == 3:\n",
    "                ax.scatter(neuron_positions[:, 0], neuron_positions[:, 1], neuron_positions[:, 2], color='red', edgecolors='k', s=100, marker='o', label='Neurony')\n",
    "            else:\n",
    "                ax.scatter(neuron_positions[:, 0], neuron_positions[:, 1], color='red', edgecolors='k', s=100, marker='o', label='Neurony')\n",
    "\n",
    "        ax.set_title('3D Clustered Data' if input_data.shape[1] == 3 else '2D Clustered Data')\n",
    "        ax.set_xlabel('Dim 1')\n",
    "        ax.set_ylabel('Dim 2')\n",
    "        if input_data.shape[1] == 3:\n",
    "            ax.set_zlabel('Dim 3')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import v_measure_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "# Assume KohonenNetwork is already implemented somewhere and imported correctly\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        images = np.fromfile(file, dtype=np.uint8).reshape(num, rows * cols)\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        _, num = struct.unpack(\">II\", file.read(8))\n",
    "        labels = np.fromfile(file, dtype=np.uint8)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "train_images = load_mnist_images('../data/2/mnist/train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "train_labels = load_mnist_labels('../data/2/mnist/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "\n",
    "test_images = load_mnist_images('../data/2/mnist/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels = load_mnist_labels('../data/2/mnist/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KohonenNetwork' object has no attribute '_find_bmu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m kohonen_network\u001b[38;5;241m.\u001b[39mtrain(train_images, train_labels, \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create a labels map\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m labels_map \u001b[38;5;241m=\u001b[39m \u001b[43mkohonen_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_labels_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Plot the labels map\u001b[39;00m\n\u001b[1;32m     15\u001b[0m kohonen_network\u001b[38;5;241m.\u001b[39mplot_labels_map(labels_map, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelf-Organizing Map with Gaussian labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mKohonenNetwork.create_labels_map\u001b[0;34m(self, input_data, labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbmu_cluster_map \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_data):\n\u001b[0;32m---> 35\u001b[0m     bmu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_bmu\u001b[49m(data)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbmu_cluster_map[bmu] \u001b[38;5;241m=\u001b[39m labels[i]\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_map[bmu][labels[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KohonenNetwork' object has no attribute '_find_bmu'"
     ]
    }
   ],
   "source": [
    "# Initialize the Kohonen Network\n",
    "kohonen_network = KohonenNetwork(20, 20, 784, neighborhood_function='gaussian')\n",
    "\n",
    "# Normalize the images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Train the network\n",
    "kohonen_network.train(train_images, train_labels, 1000)\n",
    "\n",
    "# Create a labels map\n",
    "labels_map = kohonen_network.create_labels_map(train_images, train_labels)\n",
    "\n",
    "# Plot the labels map\n",
    "kohonen_network.plot_labels_map(labels_map, 'Self-Organizing Map with Gaussian labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KohonenNetwork:\n",
    "    def __init__(self, M, N, input_dim, sigma=1.0, learning_rate=0.3, neighborhood_function='gaussian'):\n",
    "        self.M, self.N, self.input_dim = M, N, input_dim\n",
    "        self.sigma, self.learning_rate = sigma, learning_rate\n",
    "        self.neighborhood_function = neighborhood_function\n",
    "        self.weights = np.random.rand(M, N, input_dim)  # Randomly initialize weights\n",
    "\n",
    "    def train(self, input_data, num_iterations):\n",
    "        for iteration in range(num_iterations):\n",
    "            for idx in np.random.permutation(len(input_data)):\n",
    "                self._train_single_sample(input_data[idx])\n",
    "\n",
    "    def _train_single_sample(self, sample):\n",
    "        bmu_idx = self._find_bmu(sample)\n",
    "        self._update_weights(sample, bmu_idx)\n",
    "\n",
    "    def _find_bmu(self, sample):\n",
    "        # Find the best matching unit\n",
    "        distances = np.linalg.norm(self.weights - sample, axis=2)\n",
    "        return np.unravel_index(np.argmin(distances, axis=None), distances.shape)\n",
    "\n",
    "    def _update_weights(self, sample, bmu_idx):\n",
    "        # Compute the neighborhood function\n",
    "        x, y = np.ogrid[0:self.M, 0:self.N]\n",
    "        distance = np.sqrt((x - bmu_idx[0])**2 + (y - bmu_idx[1])**2)\n",
    "        influence = self._neighborhood_function(distance, self.sigma)\n",
    "        # Update weights\n",
    "        self.weights += self.learning_rate * influence[..., np.newaxis] * (sample - self.weights)\n",
    "\n",
    "    def _neighborhood_function(self, distance, sigma):\n",
    "        if self.neighborhood_function == 'gaussian':\n",
    "            return np.exp(-distance**2 / (2 * sigma**2))\n",
    "        elif self.neighborhood_function == 'mexican_hat':\n",
    "            return (1 - (distance**2 / sigma**2)) * np.exp(-distance**2 / (2 * sigma**2))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown neighborhood function\")\n",
    "\n",
    "    def visualize_map(self, input_data):\n",
    "        label_map = np.zeros((self.M, self.N))\n",
    "        for i in range(self.M):\n",
    "            for j in range(self.N):\n",
    "                distances = np.linalg.norm(input_data - self.weights[i, j], axis=1)\n",
    "                label_map[i, j] = np.argmin(distances)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(label_map, cmap='viridis', interpolation='none')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m kohonen \u001b[38;5;241m=\u001b[39m KohonenNetwork(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m784\u001b[39m)  \u001b[38;5;66;03m# Assuming 28x28 images, hence 784 input dimensions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the network\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mkohonen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate the network or use it for further analysis\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mKohonenNetwork.train\u001b[0;34m(self, input_data, num_iterations)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(input_data)):\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_single_sample(input_data[idx])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normalize the image data to [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape data if necessary (here, flattening is already done by the load function)\n",
    "# train_images = train_images.reshape((train_images.shape[0], -1))\n",
    "# test_images = test_images.reshape((test_images.shape[0], -1))\n",
    "\n",
    "# Initialize the Kohonen Network\n",
    "kohonen = KohonenNetwork(20, 20, 784)  # Assuming 28x28 images, hence 784 input dimensions\n",
    "\n",
    "# Train the network\n",
    "kohonen.train(train_images,  100)\n",
    "\n",
    "# Evaluate the network or use it for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kohonen.visualize_map(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
